{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <center> Joaquin Peñuela-Parra </center>\n",
    "<center> Department of Mechanical Engineering and Materials Science </center>\n",
    "<center> University of Pittsburgh, Pittsburgh, Pennsylvania 15261, USA </center>  -->\n",
    "\n",
    "$$ \\textrm{Joaquin Penuela-Parra} $$\n",
    "$$ \\textrm{Department of Mechanical Engineering and Materials Science} $$\n",
    "$$ \\textrm{University of Pittsburgh, Pittsburgh, Pennsylvania 15261, USA} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ITensors\n",
    "using CUDA #Nvidia GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.DeviceIterator() for 2 devices:\n",
       "0. Tesla V100-SXM2-32GB\n",
       "1. Tesla V100-SXM2-32GB"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 0.95% (309.812 MiB/31.739 GiB)\n",
      "Memory pool usage: 0 bytes (0 bytes reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general to use GPU with just need to use the function cu() or NDTensors.cu() to define the same ITensor Object inside the GPU Memory as a CUArray. The only difference between the two functions is that NDTensors.cu() preserves the element type of the tensors, while cu() converts to single precision. However, **single precision can generate problems in DMRG or TEBD** algorithms: https://itensor.discourse.group/t/tebd-with-gpu-error-with-eigen/1266/5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Block Sparse contraction**\n",
    "\n",
    "Despite this type of contractions are still in development (https://itensor.discourse.group/t/ann-initial-release-of-new-itensor-gpu-backends/1227/3), we already can see some advantage of the use of GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.041441 seconds (64 allocations: 30.526 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=663)'' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=663) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float64, Vector{Float64}, 2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#woGPU\n",
    "i = Index([QN(0) => 1000, QN(1) => 1000]);\n",
    "A = randomITensor(i', dag(i));\n",
    "\n",
    "@time (A)'*(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000311 seconds (196 allocations: 11.594 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=663)'' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=663) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float64, CuArray{Float64, 1, CUDA.DeviceMemory}, 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "A = NDTensors.cu(A)\n",
    "\n",
    "@time (A)'*(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If A is a CuArray and we define another variable in terms of A, that variable will be also a CuArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=663)' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=663) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float64, CuArray{Float64, 1, CUDA.DeviceMemory}, 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = 2*A - 3*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000294 seconds (196 allocations: 11.594 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=663)'' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=663) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float64, CuArray{Float64, 1, CUDA.DeviceMemory}, 2}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time (C)'*(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expectation values contractions (inner and apply functions)**\n",
    "\n",
    "Pure states: $\\langle A \\rangle = \\langle \\Psi | A | \\Psi \\rangle$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.082095 seconds (66.47 k allocations: 933.940 MiB, 0.63% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.011871043689372e-16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#woGPU\n",
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 200 #The difference between times increases with this value.\n",
    "\n",
    "A = randomMPS(sites, bond_dimension)\n",
    "O = randomMPO(sites)\n",
    "\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.287469 seconds (169.26 k allocations: 19.633 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.0118710440304213e-16"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "A = NDTensors.cu(A)\n",
    "O = NDTensors.cu(O)\n",
    "\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed States: $\\langle A \\rangle = \\textrm{Tr} (\\rho A)$. Take for example when $\\rho$ is an identity matrix, and A is a random operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.019085 seconds (115.77 k allocations: 30.298 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.960801096832753e-20"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#woGPU\n",
    "ρ = MPO(sites, \"Id\")\n",
    "O = randomMPO(sites)\n",
    "\n",
    "@time tr(apply(ρ, O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.124633 seconds (277.64 k allocations: 34.710 MiB)\n",
      "  0.158602 seconds (272.62 k allocations: 37.238 MiB, 11.88% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9608010968325657e-20"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "ρ = NDTensors.cu(ρ)\n",
    "O = NDTensors.cu(O)\n",
    "\n",
    "@time tr(apply(ρ, O))\n",
    "\n",
    "#We also can perform the trace manually by contracting the bra and ket site indices of each site with delta tensors. This takes a similar time:\n",
    "I = MPO(sites, \"Id\") #Contains all the delta tensors.\n",
    "I = NDTensors.cu(I)\n",
    "\n",
    "@time inner(I, apply(ρ, O))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why it is not faster?**. I think that in this case we do not see advantage because the bond dimension of $ρ$ is 1. If we have an MPO with a bigger bond dimension, probably we will see the advantage as in the case of MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=274|\"S=1/2,Site,n=1\")', (dim=2|id=274|\"S=1/2,Site,n=1\"), (dim=1|id=80|\"Link,l=1\"))\n",
       "[2] ((dim=2|id=372|\"S=1/2,Site,n=2\")', (dim=2|id=372|\"S=1/2,Site,n=2\"), (dim=1|id=242|\"Link,l=2\"), (dim=1|id=80|\"Link,l=1\"))\n",
       "[3] ((dim=2|id=120|\"S=1/2,Site,n=3\")', (dim=2|id=120|\"S=1/2,Site,n=3\"), (dim=1|id=391|\"Link,l=3\"), (dim=1|id=242|\"Link,l=2\"))\n",
       "[4] ((dim=2|id=491|\"S=1/2,Site,n=4\")', (dim=2|id=491|\"S=1/2,Site,n=4\"), (dim=1|id=673|\"Link,l=4\"), (dim=1|id=391|\"Link,l=3\"))\n",
       "[5] ((dim=2|id=414|\"S=1/2,Site,n=5\")', (dim=2|id=414|\"S=1/2,Site,n=5\"), (dim=1|id=177|\"Link,l=5\"), (dim=1|id=673|\"Link,l=4\"))\n",
       "[6] ((dim=2|id=818|\"S=1/2,Site,n=6\")', (dim=2|id=818|\"S=1/2,Site,n=6\"), (dim=1|id=551|\"Link,l=6\"), (dim=1|id=177|\"Link,l=5\"))\n",
       "[7] ((dim=2|id=98|\"S=1/2,Site,n=7\")', (dim=2|id=98|\"S=1/2,Site,n=7\"), (dim=1|id=749|\"Link,l=7\"), (dim=1|id=551|\"Link,l=6\"))\n",
       "[8] ((dim=2|id=906|\"S=1/2,Site,n=8\")', (dim=2|id=906|\"S=1/2,Site,n=8\"), (dim=1|id=577|\"Link,l=8\"), (dim=1|id=749|\"Link,l=7\"))\n",
       "[9] ((dim=2|id=396|\"S=1/2,Site,n=9\")', (dim=2|id=396|\"S=1/2,Site,n=9\"), (dim=1|id=171|\"Link,l=9\"), (dim=1|id=577|\"Link,l=8\"))\n",
       "[10] ((dim=2|id=347|\"S=1/2,Site,n=10\")', (dim=2|id=347|\"S=1/2,Site,n=10\"), (dim=1|id=662|\"Link,l=10\"), (dim=1|id=171|\"Link,l=9\"))\n",
       "[11] ((dim=2|id=462|\"S=1/2,Site,n=11\")', (dim=2|id=462|\"S=1/2,Site,n=11\"), (dim=1|id=977|\"Link,l=11\"), (dim=1|id=662|\"Link,l=10\"))\n",
       "[12] ((dim=2|id=751|\"S=1/2,Site,n=12\")', (dim=2|id=751|\"S=1/2,Site,n=12\"), (dim=1|id=660|\"Link,l=12\"), (dim=1|id=977|\"Link,l=11\"))\n",
       "[13] ((dim=2|id=814|\"S=1/2,Site,n=13\")', (dim=2|id=814|\"S=1/2,Site,n=13\"), (dim=1|id=2|\"Link,l=13\"), (dim=1|id=660|\"Link,l=12\"))\n",
       "[14] ((dim=2|id=798|\"S=1/2,Site,n=14\")', (dim=2|id=798|\"S=1/2,Site,n=14\"), (dim=1|id=183|\"Link,l=14\"), (dim=1|id=2|\"Link,l=13\"))\n",
       "[15] ((dim=2|id=311|\"S=1/2,Site,n=15\")', (dim=2|id=311|\"S=1/2,Site,n=15\"), (dim=1|id=984|\"Link,l=15\"), (dim=1|id=183|\"Link,l=14\"))\n",
       "[16] ((dim=2|id=593|\"S=1/2,Site,n=16\")', (dim=2|id=593|\"S=1/2,Site,n=16\"), (dim=1|id=791|\"Link,l=16\"), (dim=1|id=984|\"Link,l=15\"))\n",
       "[17] ((dim=2|id=43|\"S=1/2,Site,n=17\")', (dim=2|id=43|\"S=1/2,Site,n=17\"), (dim=1|id=734|\"Link,l=17\"), (dim=1|id=791|\"Link,l=16\"))\n",
       "[18] ((dim=2|id=161|\"S=1/2,Site,n=18\")', (dim=2|id=161|\"S=1/2,Site,n=18\"), (dim=1|id=767|\"Link,l=18\"), (dim=1|id=734|\"Link,l=17\"))\n",
       "[19] ((dim=2|id=80|\"S=1/2,Site,n=19\")', (dim=2|id=80|\"S=1/2,Site,n=19\"), (dim=1|id=346|\"Link,l=19\"), (dim=1|id=767|\"Link,l=18\"))\n",
       "[20] ((dim=2|id=142|\"S=1/2,Site,n=20\")', (dim=2|id=142|\"S=1/2,Site,n=20\"), (dim=1|id=442|\"Link,l=20\"), (dim=1|id=346|\"Link,l=19\"))\n",
       "[21] ((dim=2|id=374|\"S=1/2,Site,n=21\")', (dim=2|id=374|\"S=1/2,Site,n=21\"), (dim=1|id=201|\"Link,l=21\"), (dim=1|id=442|\"Link,l=20\"))\n",
       "[22] ((dim=2|id=455|\"S=1/2,Site,n=22\")', (dim=2|id=455|\"S=1/2,Site,n=22\"), (dim=1|id=194|\"Link,l=22\"), (dim=1|id=201|\"Link,l=21\"))\n",
       "[23] ((dim=2|id=100|\"S=1/2,Site,n=23\")', (dim=2|id=100|\"S=1/2,Site,n=23\"), (dim=1|id=891|\"Link,l=23\"), (dim=1|id=194|\"Link,l=22\"))\n",
       "[24] ((dim=2|id=647|\"S=1/2,Site,n=24\")', (dim=2|id=647|\"S=1/2,Site,n=24\"), (dim=1|id=731|\"Link,l=24\"), (dim=1|id=891|\"Link,l=23\"))\n",
       "[25] ((dim=2|id=585|\"S=1/2,Site,n=25\")', (dim=2|id=585|\"S=1/2,Site,n=25\"), (dim=1|id=248|\"Link,l=25\"), (dim=1|id=731|\"Link,l=24\"))\n",
       "[26] ((dim=2|id=982|\"S=1/2,Site,n=26\")', (dim=2|id=982|\"S=1/2,Site,n=26\"), (dim=1|id=245|\"Link,l=26\"), (dim=1|id=248|\"Link,l=25\"))\n",
       "[27] ((dim=2|id=249|\"S=1/2,Site,n=27\")', (dim=2|id=249|\"S=1/2,Site,n=27\"), (dim=1|id=117|\"Link,l=27\"), (dim=1|id=245|\"Link,l=26\"))\n",
       "[28] ((dim=2|id=109|\"S=1/2,Site,n=28\")', (dim=2|id=109|\"S=1/2,Site,n=28\"), (dim=1|id=315|\"Link,l=28\"), (dim=1|id=117|\"Link,l=27\"))\n",
       "[29] ((dim=2|id=373|\"S=1/2,Site,n=29\")', (dim=2|id=373|\"S=1/2,Site,n=29\"), (dim=1|id=77|\"Link,l=29\"), (dim=1|id=315|\"Link,l=28\"))\n",
       "[30] ((dim=2|id=390|\"S=1/2,Site,n=30\")', (dim=2|id=390|\"S=1/2,Site,n=30\"), (dim=1|id=356|\"Link,l=30\"), (dim=1|id=77|\"Link,l=29\"))\n",
       "[31] ((dim=2|id=504|\"S=1/2,Site,n=31\")', (dim=2|id=504|\"S=1/2,Site,n=31\"), (dim=1|id=886|\"Link,l=31\"), (dim=1|id=356|\"Link,l=30\"))\n",
       "[32] ((dim=2|id=42|\"S=1/2,Site,n=32\")', (dim=2|id=42|\"S=1/2,Site,n=32\"), (dim=1|id=542|\"Link,l=32\"), (dim=1|id=886|\"Link,l=31\"))\n",
       "[33] ((dim=2|id=872|\"S=1/2,Site,n=33\")', (dim=2|id=872|\"S=1/2,Site,n=33\"), (dim=1|id=889|\"Link,l=33\"), (dim=1|id=542|\"Link,l=32\"))\n",
       "[34] ((dim=2|id=4|\"S=1/2,Site,n=34\")', (dim=2|id=4|\"S=1/2,Site,n=34\"), (dim=1|id=576|\"Link,l=34\"), (dim=1|id=889|\"Link,l=33\"))\n",
       "[35] ((dim=2|id=274|\"S=1/2,Site,n=35\")', (dim=2|id=274|\"S=1/2,Site,n=35\"), (dim=1|id=226|\"Link,l=35\"), (dim=1|id=576|\"Link,l=34\"))\n",
       "[36] ((dim=2|id=741|\"S=1/2,Site,n=36\")', (dim=2|id=741|\"S=1/2,Site,n=36\"), (dim=1|id=708|\"Link,l=36\"), (dim=1|id=226|\"Link,l=35\"))\n",
       "[37] ((dim=2|id=53|\"S=1/2,Site,n=37\")', (dim=2|id=53|\"S=1/2,Site,n=37\"), (dim=1|id=35|\"Link,l=37\"), (dim=1|id=708|\"Link,l=36\"))\n",
       "[38] ((dim=2|id=806|\"S=1/2,Site,n=38\")', (dim=2|id=806|\"S=1/2,Site,n=38\"), (dim=1|id=479|\"Link,l=38\"), (dim=1|id=35|\"Link,l=37\"))\n",
       "[39] ((dim=2|id=573|\"S=1/2,Site,n=39\")', (dim=2|id=573|\"S=1/2,Site,n=39\"), (dim=1|id=123|\"Link,l=39\"), (dim=1|id=479|\"Link,l=38\"))\n",
       "[40] ((dim=2|id=42|\"S=1/2,Site,n=40\")', (dim=2|id=42|\"S=1/2,Site,n=40\"), (dim=1|id=691|\"Link,l=40\"), (dim=1|id=123|\"Link,l=39\"))\n",
       "[41] ((dim=2|id=129|\"S=1/2,Site,n=41\")', (dim=2|id=129|\"S=1/2,Site,n=41\"), (dim=1|id=340|\"Link,l=41\"), (dim=1|id=691|\"Link,l=40\"))\n",
       "[42] ((dim=2|id=931|\"S=1/2,Site,n=42\")', (dim=2|id=931|\"S=1/2,Site,n=42\"), (dim=1|id=674|\"Link,l=42\"), (dim=1|id=340|\"Link,l=41\"))\n",
       "[43] ((dim=2|id=551|\"S=1/2,Site,n=43\")', (dim=2|id=551|\"S=1/2,Site,n=43\"), (dim=1|id=43|\"Link,l=43\"), (dim=1|id=674|\"Link,l=42\"))\n",
       "[44] ((dim=2|id=722|\"S=1/2,Site,n=44\")', (dim=2|id=722|\"S=1/2,Site,n=44\"), (dim=1|id=782|\"Link,l=44\"), (dim=1|id=43|\"Link,l=43\"))\n",
       "[45] ((dim=2|id=378|\"S=1/2,Site,n=45\")', (dim=2|id=378|\"S=1/2,Site,n=45\"), (dim=1|id=984|\"Link,l=45\"), (dim=1|id=782|\"Link,l=44\"))\n",
       "[46] ((dim=2|id=887|\"S=1/2,Site,n=46\")', (dim=2|id=887|\"S=1/2,Site,n=46\"), (dim=1|id=301|\"Link,l=46\"), (dim=1|id=984|\"Link,l=45\"))\n",
       "[47] ((dim=2|id=428|\"S=1/2,Site,n=47\")', (dim=2|id=428|\"S=1/2,Site,n=47\"), (dim=1|id=660|\"Link,l=47\"), (dim=1|id=301|\"Link,l=46\"))\n",
       "[48] ((dim=2|id=925|\"S=1/2,Site,n=48\")', (dim=2|id=925|\"S=1/2,Site,n=48\"), (dim=1|id=947|\"Link,l=48\"), (dim=1|id=660|\"Link,l=47\"))\n",
       "[49] ((dim=2|id=80|\"S=1/2,Site,n=49\")', (dim=2|id=80|\"S=1/2,Site,n=49\"), (dim=1|id=110|\"Link,l=49\"), (dim=1|id=947|\"Link,l=48\"))\n",
       "[50] ((dim=2|id=565|\"S=1/2,Site,n=50\")', (dim=2|id=565|\"S=1/2,Site,n=50\"), (dim=1|id=110|\"Link,l=49\"))\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ρ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Garbage Collection** (references: https://cuda.juliagpu.org/stable/usage/memory/ and https://discourse.julialang.org/t/any-way-to-delete-an-object-and-free-memory/53600)\n",
    "\n",
    "This can be monitored using the Task Manager of Windows or using CUDA.memory_status():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 6.58% (2.090 GiB/31.739 GiB)\n",
      "Memory pool usage: 152.591 MiB (352.000 MiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11.373794 seconds (66.92 k allocations: 7.421 GiB, 10.10% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-5.343098905360732e-16"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#woGPU\n",
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 600 #The difference between times increases with this value.\n",
    "\n",
    "A = randomMPS(sites, bond_dimension)\n",
    "O = randomMPO(sites)\n",
    "\n",
    "@time begin \n",
    "    inner(A, apply(O, A))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.824254 seconds (178.78 k allocations: 20.642 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-5.343098909471342e-16"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "A = NDTensors.cu(A)\n",
    "O = NDTensors.cu(O)\n",
    "\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As A has a bond_dimension of 600, the GPU used a lot of memory to perform the last operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 29.20% (9.267 GiB/31.739 GiB)\n",
      "Memory pool usage: 7.050 GiB (8.812 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Task Manager](CUDA_1.png)  -->\n",
    "\n",
    "<!-- <img src=\"CUDA_1.png\" alt=\"alt text\" width=\"400\" height=\"400\"/> -->\n",
    "\n",
    "If we try to run the code again, we must be careful because it could be slow because we do not have more GPU memory and ITensors has not clean all the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 54.11% (17.174 GiB/31.739 GiB)\n",
      "Memory pool usage: 3.726 GiB (16.719 GiB reserved)\n",
      "  0.809060 seconds (178.84 k allocations: 20.646 MiB, 1.14% gc time)\n",
      "Effective GPU memory usage: 54.11% (17.174 GiB/31.739 GiB)\n",
      "Memory pool usage: 10.411 GiB (16.719 GiB reserved)\n",
      "  0.789810 seconds (178.96 k allocations: 20.657 MiB)\n",
      "Effective GPU memory usage: 54.11% (17.174 GiB/31.739 GiB)\n",
      "Memory pool usage: 2.052 GiB (16.719 GiB reserved)\n",
      "  0.812577 seconds (178.97 k allocations: 20.657 MiB, 1.19% gc time)\n",
      "Effective GPU memory usage: 54.11% (17.174 GiB/31.739 GiB)\n",
      "Memory pool usage: 8.736 GiB (16.719 GiB reserved)\n",
      "  0.788708 seconds (178.96 k allocations: 20.657 MiB)\n",
      "Effective GPU memory usage: 54.11% (17.174 GiB/31.739 GiB)\n",
      "Memory pool usage: 15.421 GiB (16.719 GiB reserved)\n",
      "  0.793084 seconds (178.97 k allocations: 20.657 MiB)\n",
      "Effective GPU memory usage: 54.50% (17.299 GiB/31.739 GiB)\n",
      "Memory pool usage: 5.751 GiB (16.844 GiB reserved)\n",
      "  0.800891 seconds (178.96 k allocations: 20.657 MiB, 1.50% gc time)\n",
      "Effective GPU memory usage: 54.50% (17.299 GiB/31.739 GiB)\n",
      "Memory pool usage: 12.436 GiB (16.844 GiB reserved)\n",
      "  0.789365 seconds (178.96 k allocations: 20.657 MiB)\n",
      "Effective GPU memory usage: 54.50% (17.299 GiB/31.739 GiB)\n",
      "Memory pool usage: 4.005 GiB (16.844 GiB reserved)\n",
      "  0.814950 seconds (178.96 k allocations: 20.657 MiB, 1.25% gc time)\n",
      "Effective GPU memory usage: 54.50% (17.299 GiB/31.739 GiB)\n",
      "Memory pool usage: 10.690 GiB (16.844 GiB reserved)\n",
      "  0.788307 seconds (178.96 k allocations: 20.657 MiB)\n",
      "Effective GPU memory usage: 54.50% (17.299 GiB/31.739 GiB)\n",
      "Memory pool usage: 2.331 GiB (16.844 GiB reserved)\n",
      "  0.811249 seconds (178.97 k allocations: 20.657 MiB, 1.17% gc time)\n"
     ]
    }
   ],
   "source": [
    "for i = 1:10\n",
    "    @time begin \n",
    "        inner(A, apply(O, A))\n",
    "        CUDA.memory_status()    \n",
    "        # CUDA.reclaim()\n",
    "        # CUDA.memory_status()    \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we do not have more GPU the computer starts using the shared GPU memory (i.e. RAM), this generates a bottle neck and it could be even slower than just using CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 54.11% (17.174 GiB/31.739 GiB)\n",
      "Memory pool usage: 5.751 GiB (16.719 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to recover all the memory used to save the chache of the calculation we need to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.452791 seconds (98.26% gc time)\n",
      "  0.044091 seconds (10 allocations: 608 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time GC.gc(true)\n",
    "@time CUDA.reclaim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 19.84% (6.299 GiB/31.739 GiB)\n",
      "Memory pool usage: 5.751 GiB (5.844 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we clean in each step of the for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.796158 seconds (178.78 k allocations: 20.643 MiB)\n",
      "  0.466342 seconds (10 allocations: 608 bytes, 93.54% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.801689 seconds (178.77 k allocations: 20.643 MiB)\n",
      "  0.492212 seconds (10 allocations: 608 bytes, 94.12% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.814620 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.518652 seconds (10 allocations: 608 bytes, 93.98% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.804223 seconds (178.77 k allocations: 20.643 MiB)\n",
      "  0.480974 seconds (10 allocations: 608 bytes, 93.75% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.808694 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.453822 seconds (10 allocations: 608 bytes, 92.94% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.828224 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.437730 seconds (10 allocations: 608 bytes, 92.39% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.809149 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.445783 seconds (10 allocations: 608 bytes, 93.32% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.811245 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.491196 seconds (10 allocations: 608 bytes, 93.97% gc time)\n"
     ]
    }
   ],
   "source": [
    "for i = 1:8\n",
    "    @time begin \n",
    "        inner(A, apply(O, A))\n",
    "        CUDA.memory_status()    \n",
    "    end\n",
    "    @time begin\n",
    "        GC.gc(true)\n",
    "        CUDA.reclaim()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 20.81% (1.664 GiB/7.996 GiB)\n",
      "Memory pool usage: 481.346 MiB (512.000 MiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works, is better for the memory also takes some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple GPUs** https://cuda.juliagpu.org/stable/usage/multigpu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_all_gpus (generic function with 1 method)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#monitoring multiples gpu functions:\n",
    "\n",
    "function memory_info_all_gpus(print_info = true)\n",
    "    \n",
    "    percentages = []\n",
    "\n",
    "    scale = 1/(1024^3) #converty bytes to GB\n",
    "    for (i, dev) in enumerate(CUDA.NVML.devices())\n",
    "\n",
    "        name = CUDA.NVML.name(dev) \n",
    "        mem_info = CUDA.NVML.memory_info(dev)\n",
    "        total = round(mem_info.total*scale, sigdigits=4)\n",
    "        used = round(mem_info.used*scale, sigdigits=4)\n",
    "        free = round(mem_info.free*scale, sigdigits=4)\n",
    "        percentage= round(used*100/total, sigdigits=4)\n",
    "        \n",
    "        print_info ? println(\"$name #$i memory usage: $percentage % ($used GB/ $total GB)\" ) : nothing\n",
    "        \n",
    "        append!(percentages, percentage)\n",
    "    end\n",
    "    \n",
    "    return percentages\n",
    "end\n",
    "\n",
    "function clean_all_gpus()\n",
    "    for i=reverse(0:length(CUDA.devices()) - 1)\n",
    "        global current_gpu = i\n",
    "        CUDA.device!(current_gpu)\n",
    "        GC.gc(true) \n",
    "        CUDA.reclaim()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 5.775 % (1.848 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 5.775\n",
       " 1.76"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 7.894 % (2.526 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 7.894\n",
       " 1.76"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 2000 #The difference between times increases with this value.\n",
    "\n",
    "#wGPU\n",
    "A = cu(randomMPS(sites, bond_dimension); unified=true)\n",
    "O = cu(randomMPO(sites); unified=true)\n",
    "\n",
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10.841058 seconds (247.56 k allocations: 23.779 MiB, 0.07% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0127992f-7"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.889455 seconds (247.31 k allocations: 22.917 MiB)\n",
      " 14.197200 seconds (247.53 k allocations: 22.930 MiB)\n",
      " 19.496476 seconds (247.56 k allocations: 22.931 MiB)\n"
     ]
    }
   ],
   "source": [
    "for i=1:5\n",
    "    @time inner(A, apply(O, A))\n",
    "    memory_info_all_gpus()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 20.74 % (6.637 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 20.74\n",
       "  1.76"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.879115 seconds (22 allocations: 1.219 KiB, 99.97% gc time)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 7.344 % (2.35 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 7.344\n",
       " 1.76"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time clean_all_gpus()\n",
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000008 seconds\n",
      "  0.438500 seconds (99.98% gc time)\n",
      "  0.000059 seconds (10 allocations: 608 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time device!(0)\n",
    "@time GC.gc(true) \n",
    "@time CUDA.reclaim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dev in devices()\n",
    "#     # NOTE: normally you'd use events and wait for them\n",
    "#     device!(dev)\n",
    "#     synchronize()\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.441875 seconds (99.98% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time GC.gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unified is really important or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_all_gpus()\n",
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=887|\"S=1/2,Site,n=1\")', (dim=2|id=887|\"S=1/2,Site,n=1\"), (dim=1|id=778|\"Link,l=1\"))\n",
       "[2] ((dim=2|id=62|\"S=1/2,Site,n=2\")', (dim=2|id=62|\"S=1/2,Site,n=2\"), (dim=1|id=855|\"Link,l=2\"), (dim=1|id=778|\"Link,l=1\"))\n",
       "[3] ((dim=2|id=128|\"S=1/2,Site,n=3\")', (dim=2|id=128|\"S=1/2,Site,n=3\"), (dim=1|id=207|\"Link,l=3\"), (dim=1|id=855|\"Link,l=2\"))\n",
       "[4] ((dim=2|id=927|\"S=1/2,Site,n=4\")', (dim=2|id=927|\"S=1/2,Site,n=4\"), (dim=1|id=315|\"Link,l=4\"), (dim=1|id=207|\"Link,l=3\"))\n",
       "[5] ((dim=2|id=312|\"S=1/2,Site,n=5\")', (dim=2|id=312|\"S=1/2,Site,n=5\"), (dim=1|id=909|\"Link,l=5\"), (dim=1|id=315|\"Link,l=4\"))\n",
       "[6] ((dim=2|id=86|\"S=1/2,Site,n=6\")', (dim=2|id=86|\"S=1/2,Site,n=6\"), (dim=1|id=375|\"Link,l=6\"), (dim=1|id=909|\"Link,l=5\"))\n",
       "[7] ((dim=2|id=706|\"S=1/2,Site,n=7\")', (dim=2|id=706|\"S=1/2,Site,n=7\"), (dim=1|id=964|\"Link,l=7\"), (dim=1|id=375|\"Link,l=6\"))\n",
       "[8] ((dim=2|id=439|\"S=1/2,Site,n=8\")', (dim=2|id=439|\"S=1/2,Site,n=8\"), (dim=1|id=611|\"Link,l=8\"), (dim=1|id=964|\"Link,l=7\"))\n",
       "[9] ((dim=2|id=449|\"S=1/2,Site,n=9\")', (dim=2|id=449|\"S=1/2,Site,n=9\"), (dim=1|id=319|\"Link,l=9\"), (dim=1|id=611|\"Link,l=8\"))\n",
       "[10] ((dim=2|id=419|\"S=1/2,Site,n=10\")', (dim=2|id=419|\"S=1/2,Site,n=10\"), (dim=1|id=301|\"Link,l=10\"), (dim=1|id=319|\"Link,l=9\"))\n",
       "[11] ((dim=2|id=301|\"S=1/2,Site,n=11\")', (dim=2|id=301|\"S=1/2,Site,n=11\"), (dim=1|id=242|\"Link,l=11\"), (dim=1|id=301|\"Link,l=10\"))\n",
       "[12] ((dim=2|id=363|\"S=1/2,Site,n=12\")', (dim=2|id=363|\"S=1/2,Site,n=12\"), (dim=1|id=828|\"Link,l=12\"), (dim=1|id=242|\"Link,l=11\"))\n",
       "[13] ((dim=2|id=916|\"S=1/2,Site,n=13\")', (dim=2|id=916|\"S=1/2,Site,n=13\"), (dim=1|id=5|\"Link,l=13\"), (dim=1|id=828|\"Link,l=12\"))\n",
       "[14] ((dim=2|id=330|\"S=1/2,Site,n=14\")', (dim=2|id=330|\"S=1/2,Site,n=14\"), (dim=1|id=497|\"Link,l=14\"), (dim=1|id=5|\"Link,l=13\"))\n",
       "[15] ((dim=2|id=24|\"S=1/2,Site,n=15\")', (dim=2|id=24|\"S=1/2,Site,n=15\"), (dim=1|id=337|\"Link,l=15\"), (dim=1|id=497|\"Link,l=14\"))\n",
       "[16] ((dim=2|id=256|\"S=1/2,Site,n=16\")', (dim=2|id=256|\"S=1/2,Site,n=16\"), (dim=1|id=245|\"Link,l=16\"), (dim=1|id=337|\"Link,l=15\"))\n",
       "[17] ((dim=2|id=540|\"S=1/2,Site,n=17\")', (dim=2|id=540|\"S=1/2,Site,n=17\"), (dim=1|id=303|\"Link,l=17\"), (dim=1|id=245|\"Link,l=16\"))\n",
       "[18] ((dim=2|id=523|\"S=1/2,Site,n=18\")', (dim=2|id=523|\"S=1/2,Site,n=18\"), (dim=1|id=482|\"Link,l=18\"), (dim=1|id=303|\"Link,l=17\"))\n",
       "[19] ((dim=2|id=105|\"S=1/2,Site,n=19\")', (dim=2|id=105|\"S=1/2,Site,n=19\"), (dim=1|id=318|\"Link,l=19\"), (dim=1|id=482|\"Link,l=18\"))\n",
       "[20] ((dim=2|id=604|\"S=1/2,Site,n=20\")', (dim=2|id=604|\"S=1/2,Site,n=20\"), (dim=1|id=628|\"Link,l=20\"), (dim=1|id=318|\"Link,l=19\"))\n",
       "[21] ((dim=2|id=709|\"S=1/2,Site,n=21\")', (dim=2|id=709|\"S=1/2,Site,n=21\"), (dim=1|id=124|\"Link,l=21\"), (dim=1|id=628|\"Link,l=20\"))\n",
       "[22] ((dim=2|id=599|\"S=1/2,Site,n=22\")', (dim=2|id=599|\"S=1/2,Site,n=22\"), (dim=1|id=527|\"Link,l=22\"), (dim=1|id=124|\"Link,l=21\"))\n",
       "[23] ((dim=2|id=273|\"S=1/2,Site,n=23\")', (dim=2|id=273|\"S=1/2,Site,n=23\"), (dim=1|id=265|\"Link,l=23\"), (dim=1|id=527|\"Link,l=22\"))\n",
       "[24] ((dim=2|id=86|\"S=1/2,Site,n=24\")', (dim=2|id=86|\"S=1/2,Site,n=24\"), (dim=1|id=840|\"Link,l=24\"), (dim=1|id=265|\"Link,l=23\"))\n",
       "[25] ((dim=2|id=839|\"S=1/2,Site,n=25\")', (dim=2|id=839|\"S=1/2,Site,n=25\"), (dim=1|id=409|\"Link,l=25\"), (dim=1|id=840|\"Link,l=24\"))\n",
       "[26] ((dim=2|id=310|\"S=1/2,Site,n=26\")', (dim=2|id=310|\"S=1/2,Site,n=26\"), (dim=1|id=704|\"Link,l=26\"), (dim=1|id=409|\"Link,l=25\"))\n",
       "[27] ((dim=2|id=823|\"S=1/2,Site,n=27\")', (dim=2|id=823|\"S=1/2,Site,n=27\"), (dim=1|id=652|\"Link,l=27\"), (dim=1|id=704|\"Link,l=26\"))\n",
       "[28] ((dim=2|id=503|\"S=1/2,Site,n=28\")', (dim=2|id=503|\"S=1/2,Site,n=28\"), (dim=1|id=520|\"Link,l=28\"), (dim=1|id=652|\"Link,l=27\"))\n",
       "[29] ((dim=2|id=694|\"S=1/2,Site,n=29\")', (dim=2|id=694|\"S=1/2,Site,n=29\"), (dim=1|id=822|\"Link,l=29\"), (dim=1|id=520|\"Link,l=28\"))\n",
       "[30] ((dim=2|id=363|\"S=1/2,Site,n=30\")', (dim=2|id=363|\"S=1/2,Site,n=30\"), (dim=1|id=92|\"Link,l=30\"), (dim=1|id=822|\"Link,l=29\"))\n",
       "[31] ((dim=2|id=568|\"S=1/2,Site,n=31\")', (dim=2|id=568|\"S=1/2,Site,n=31\"), (dim=1|id=415|\"Link,l=31\"), (dim=1|id=92|\"Link,l=30\"))\n",
       "[32] ((dim=2|id=114|\"S=1/2,Site,n=32\")', (dim=2|id=114|\"S=1/2,Site,n=32\"), (dim=1|id=292|\"Link,l=32\"), (dim=1|id=415|\"Link,l=31\"))\n",
       "[33] ((dim=2|id=425|\"S=1/2,Site,n=33\")', (dim=2|id=425|\"S=1/2,Site,n=33\"), (dim=1|id=318|\"Link,l=33\"), (dim=1|id=292|\"Link,l=32\"))\n",
       "[34] ((dim=2|id=470|\"S=1/2,Site,n=34\")', (dim=2|id=470|\"S=1/2,Site,n=34\"), (dim=1|id=373|\"Link,l=34\"), (dim=1|id=318|\"Link,l=33\"))\n",
       "[35] ((dim=2|id=154|\"S=1/2,Site,n=35\")', (dim=2|id=154|\"S=1/2,Site,n=35\"), (dim=1|id=816|\"Link,l=35\"), (dim=1|id=373|\"Link,l=34\"))\n",
       "[36] ((dim=2|id=470|\"S=1/2,Site,n=36\")', (dim=2|id=470|\"S=1/2,Site,n=36\"), (dim=1|id=380|\"Link,l=36\"), (dim=1|id=816|\"Link,l=35\"))\n",
       "[37] ((dim=2|id=709|\"S=1/2,Site,n=37\")', (dim=2|id=709|\"S=1/2,Site,n=37\"), (dim=1|id=328|\"Link,l=37\"), (dim=1|id=380|\"Link,l=36\"))\n",
       "[38] ((dim=2|id=360|\"S=1/2,Site,n=38\")', (dim=2|id=360|\"S=1/2,Site,n=38\"), (dim=1|id=495|\"Link,l=38\"), (dim=1|id=328|\"Link,l=37\"))\n",
       "[39] ((dim=2|id=797|\"S=1/2,Site,n=39\")', (dim=2|id=797|\"S=1/2,Site,n=39\"), (dim=1|id=689|\"Link,l=39\"), (dim=1|id=495|\"Link,l=38\"))\n",
       "[40] ((dim=2|id=67|\"S=1/2,Site,n=40\")', (dim=2|id=67|\"S=1/2,Site,n=40\"), (dim=1|id=499|\"Link,l=40\"), (dim=1|id=689|\"Link,l=39\"))\n",
       "[41] ((dim=2|id=394|\"S=1/2,Site,n=41\")', (dim=2|id=394|\"S=1/2,Site,n=41\"), (dim=1|id=174|\"Link,l=41\"), (dim=1|id=499|\"Link,l=40\"))\n",
       "[42] ((dim=2|id=986|\"S=1/2,Site,n=42\")', (dim=2|id=986|\"S=1/2,Site,n=42\"), (dim=1|id=568|\"Link,l=42\"), (dim=1|id=174|\"Link,l=41\"))\n",
       "[43] ((dim=2|id=180|\"S=1/2,Site,n=43\")', (dim=2|id=180|\"S=1/2,Site,n=43\"), (dim=1|id=11|\"Link,l=43\"), (dim=1|id=568|\"Link,l=42\"))\n",
       "[44] ((dim=2|id=34|\"S=1/2,Site,n=44\")', (dim=2|id=34|\"S=1/2,Site,n=44\"), (dim=1|id=32|\"Link,l=44\"), (dim=1|id=11|\"Link,l=43\"))\n",
       "[45] ((dim=2|id=277|\"S=1/2,Site,n=45\")', (dim=2|id=277|\"S=1/2,Site,n=45\"), (dim=1|id=136|\"Link,l=45\"), (dim=1|id=32|\"Link,l=44\"))\n",
       "[46] ((dim=2|id=198|\"S=1/2,Site,n=46\")', (dim=2|id=198|\"S=1/2,Site,n=46\"), (dim=1|id=862|\"Link,l=46\"), (dim=1|id=136|\"Link,l=45\"))\n",
       "[47] ((dim=2|id=151|\"S=1/2,Site,n=47\")', (dim=2|id=151|\"S=1/2,Site,n=47\"), (dim=1|id=996|\"Link,l=47\"), (dim=1|id=862|\"Link,l=46\"))\n",
       "[48] ((dim=2|id=93|\"S=1/2,Site,n=48\")', (dim=2|id=93|\"S=1/2,Site,n=48\"), (dim=1|id=766|\"Link,l=48\"), (dim=1|id=996|\"Link,l=47\"))\n",
       "[49] ((dim=2|id=734|\"S=1/2,Site,n=49\")', (dim=2|id=734|\"S=1/2,Site,n=49\"), (dim=1|id=920|\"Link,l=49\"), (dim=1|id=766|\"Link,l=48\"))\n",
       "[50] ((dim=2|id=949|\"S=1/2,Site,n=50\")', (dim=2|id=949|\"S=1/2,Site,n=50\"), (dim=1|id=920|\"Link,l=49\"))\n"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 1600 #The difference between times increases with this value.\n",
    "\n",
    "#wGPU\n",
    "device!(0)\n",
    "# A = cu(randomMPS(sites, bond_dimension))\n",
    "# O = cu(randomMPO(sites))\n",
    "\n",
    "# A = cu(randomMPS(sites, bond_dimension); unified=true)\n",
    "# O = cu(randomMPO(sites); unified=true)\n",
    "\n",
    "A = NDTensors.cu(randomMPS(sites, bond_dimension))\n",
    "O = NDTensors.cu(randomMPO(sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.379785 seconds (180.83 k allocations: 22.561 MiB, 0.14% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.590782771737994e-16"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device!(1)\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 12.0 % (3.841 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 12.0\n",
       "  1.76"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
