{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <center> Joaquin Peñuela-Parra </center>\n",
    "<center> Department of Mechanical Engineering and Materials Science </center>\n",
    "<center> University of Pittsburgh, Pittsburgh, Pennsylvania 15261, USA </center>  -->\n",
    "\n",
    "$$ \\textrm{Joaquin Penuela-Parra} $$\n",
    "$$ \\textrm{Department of Mechanical Engineering and Materials Science} $$\n",
    "$$ \\textrm{University of Pittsburgh, Pittsburgh, Pennsylvania 15261, USA} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ITensors\n",
    "using CUDA #Nvidia GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.DeviceIterator() for 2 devices:\n",
       "0. Tesla V100-SXM2-32GB\n",
       "1. Tesla V100-SXM2-32GB"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 0.95% (309.812 MiB/31.739 GiB)\n",
      "Memory pool usage: 0 bytes (0 bytes reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general to use ITensor with GPU, we just need to use the function cu() or NDTensors.cu() to define the same ITensor Object inside the GPU Memory as a CUArray. The only difference between the two functions is that NDTensors.cu() preserves the element type of the tensors, while cu() converts to single precision. However, **single precision can generate problems in DMRG or TEBD** algorithms: https://itensor.discourse.group/t/tebd-with-gpu-error-with-eigen/1266/5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Block Sparse contraction**\n",
    "\n",
    "Despite this type of contractions are still in development (https://itensor.discourse.group/t/ann-initial-release-of-new-itensor-gpu-backends/1227/3), we already can see some advantage of the use of GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.214567 seconds (19.54 M allocations: 1.255 GiB, 11.30% gc time, 99.51% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=518)'' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=518) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float64, Vector{Float64}, 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#woGPU\n",
    "i = Index([QN(0) => 1000, QN(1) => 1000]);\n",
    "A = randomITensor(i', dag(i));\n",
    "\n",
    "@time (A)'*(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000311 seconds (196 allocations: 11.594 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=663)'' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=663) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float64, CuArray{Float64, 1, CUDA.DeviceMemory}, 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "A = NDTensors.cu(A)\n",
    "\n",
    "@time (A)'*(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If A is a CuArray and we define another variable in terms of A, that variable will be also a CuArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=663)' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=663) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float64, CuArray{Float64, 1, CUDA.DeviceMemory}, 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = 2*A - 3*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000294 seconds (196 allocations: 11.594 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=663)'' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=663) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float64, CuArray{Float64, 1, CUDA.DeviceMemory}, 2}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time (C)'*(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expectation values contractions (inner and apply functions)**\n",
    "\n",
    "Pure states: $\\langle A \\rangle = \\langle \\Psi | A | \\Psi \\rangle$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.082095 seconds (66.47 k allocations: 933.940 MiB, 0.63% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.011871043689372e-16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#woGPU\n",
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 200 #The difference between times increases with this value.\n",
    "\n",
    "A = randomMPS(sites, bond_dimension)\n",
    "O = randomMPO(sites)\n",
    "\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.287469 seconds (169.26 k allocations: 19.633 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.0118710440304213e-16"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "A = NDTensors.cu(A)\n",
    "O = NDTensors.cu(O)\n",
    "\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed States: $\\langle A \\rangle = \\textrm{Tr} (\\rho A)$. Take for example when $\\rho$ is an identity matrix, and A is a random operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.019085 seconds (115.77 k allocations: 30.298 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.960801096832753e-20"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#woGPU\n",
    "ρ = MPO(sites, \"Id\")\n",
    "O = randomMPO(sites)\n",
    "\n",
    "@time tr(apply(ρ, O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.124633 seconds (277.64 k allocations: 34.710 MiB)\n",
      "  0.158602 seconds (272.62 k allocations: 37.238 MiB, 11.88% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.9608010968325657e-20"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "ρ = NDTensors.cu(ρ)\n",
    "O = NDTensors.cu(O)\n",
    "\n",
    "@time tr(apply(ρ, O))\n",
    "\n",
    "#We also can perform the trace manually by contracting the bra and ket site indices of each site with delta tensors. This takes a similar time:\n",
    "I = MPO(sites, \"Id\") #Contains all the delta tensors.\n",
    "I = NDTensors.cu(I)\n",
    "\n",
    "@time inner(I, apply(ρ, O))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why it is not faster?**. I think that in this case we do not see advantage because the bond dimension of $ρ$ is 1. If we have an MPO with a bigger bond dimension, probably we will see the advantage as in the case of MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=274|\"S=1/2,Site,n=1\")', (dim=2|id=274|\"S=1/2,Site,n=1\"), (dim=1|id=80|\"Link,l=1\"))\n",
       "[2] ((dim=2|id=372|\"S=1/2,Site,n=2\")', (dim=2|id=372|\"S=1/2,Site,n=2\"), (dim=1|id=242|\"Link,l=2\"), (dim=1|id=80|\"Link,l=1\"))\n",
       "[3] ((dim=2|id=120|\"S=1/2,Site,n=3\")', (dim=2|id=120|\"S=1/2,Site,n=3\"), (dim=1|id=391|\"Link,l=3\"), (dim=1|id=242|\"Link,l=2\"))\n",
       "[4] ((dim=2|id=491|\"S=1/2,Site,n=4\")', (dim=2|id=491|\"S=1/2,Site,n=4\"), (dim=1|id=673|\"Link,l=4\"), (dim=1|id=391|\"Link,l=3\"))\n",
       "[5] ((dim=2|id=414|\"S=1/2,Site,n=5\")', (dim=2|id=414|\"S=1/2,Site,n=5\"), (dim=1|id=177|\"Link,l=5\"), (dim=1|id=673|\"Link,l=4\"))\n",
       "[6] ((dim=2|id=818|\"S=1/2,Site,n=6\")', (dim=2|id=818|\"S=1/2,Site,n=6\"), (dim=1|id=551|\"Link,l=6\"), (dim=1|id=177|\"Link,l=5\"))\n",
       "[7] ((dim=2|id=98|\"S=1/2,Site,n=7\")', (dim=2|id=98|\"S=1/2,Site,n=7\"), (dim=1|id=749|\"Link,l=7\"), (dim=1|id=551|\"Link,l=6\"))\n",
       "[8] ((dim=2|id=906|\"S=1/2,Site,n=8\")', (dim=2|id=906|\"S=1/2,Site,n=8\"), (dim=1|id=577|\"Link,l=8\"), (dim=1|id=749|\"Link,l=7\"))\n",
       "[9] ((dim=2|id=396|\"S=1/2,Site,n=9\")', (dim=2|id=396|\"S=1/2,Site,n=9\"), (dim=1|id=171|\"Link,l=9\"), (dim=1|id=577|\"Link,l=8\"))\n",
       "[10] ((dim=2|id=347|\"S=1/2,Site,n=10\")', (dim=2|id=347|\"S=1/2,Site,n=10\"), (dim=1|id=662|\"Link,l=10\"), (dim=1|id=171|\"Link,l=9\"))\n",
       "[11] ((dim=2|id=462|\"S=1/2,Site,n=11\")', (dim=2|id=462|\"S=1/2,Site,n=11\"), (dim=1|id=977|\"Link,l=11\"), (dim=1|id=662|\"Link,l=10\"))\n",
       "[12] ((dim=2|id=751|\"S=1/2,Site,n=12\")', (dim=2|id=751|\"S=1/2,Site,n=12\"), (dim=1|id=660|\"Link,l=12\"), (dim=1|id=977|\"Link,l=11\"))\n",
       "[13] ((dim=2|id=814|\"S=1/2,Site,n=13\")', (dim=2|id=814|\"S=1/2,Site,n=13\"), (dim=1|id=2|\"Link,l=13\"), (dim=1|id=660|\"Link,l=12\"))\n",
       "[14] ((dim=2|id=798|\"S=1/2,Site,n=14\")', (dim=2|id=798|\"S=1/2,Site,n=14\"), (dim=1|id=183|\"Link,l=14\"), (dim=1|id=2|\"Link,l=13\"))\n",
       "[15] ((dim=2|id=311|\"S=1/2,Site,n=15\")', (dim=2|id=311|\"S=1/2,Site,n=15\"), (dim=1|id=984|\"Link,l=15\"), (dim=1|id=183|\"Link,l=14\"))\n",
       "[16] ((dim=2|id=593|\"S=1/2,Site,n=16\")', (dim=2|id=593|\"S=1/2,Site,n=16\"), (dim=1|id=791|\"Link,l=16\"), (dim=1|id=984|\"Link,l=15\"))\n",
       "[17] ((dim=2|id=43|\"S=1/2,Site,n=17\")', (dim=2|id=43|\"S=1/2,Site,n=17\"), (dim=1|id=734|\"Link,l=17\"), (dim=1|id=791|\"Link,l=16\"))\n",
       "[18] ((dim=2|id=161|\"S=1/2,Site,n=18\")', (dim=2|id=161|\"S=1/2,Site,n=18\"), (dim=1|id=767|\"Link,l=18\"), (dim=1|id=734|\"Link,l=17\"))\n",
       "[19] ((dim=2|id=80|\"S=1/2,Site,n=19\")', (dim=2|id=80|\"S=1/2,Site,n=19\"), (dim=1|id=346|\"Link,l=19\"), (dim=1|id=767|\"Link,l=18\"))\n",
       "[20] ((dim=2|id=142|\"S=1/2,Site,n=20\")', (dim=2|id=142|\"S=1/2,Site,n=20\"), (dim=1|id=442|\"Link,l=20\"), (dim=1|id=346|\"Link,l=19\"))\n",
       "[21] ((dim=2|id=374|\"S=1/2,Site,n=21\")', (dim=2|id=374|\"S=1/2,Site,n=21\"), (dim=1|id=201|\"Link,l=21\"), (dim=1|id=442|\"Link,l=20\"))\n",
       "[22] ((dim=2|id=455|\"S=1/2,Site,n=22\")', (dim=2|id=455|\"S=1/2,Site,n=22\"), (dim=1|id=194|\"Link,l=22\"), (dim=1|id=201|\"Link,l=21\"))\n",
       "[23] ((dim=2|id=100|\"S=1/2,Site,n=23\")', (dim=2|id=100|\"S=1/2,Site,n=23\"), (dim=1|id=891|\"Link,l=23\"), (dim=1|id=194|\"Link,l=22\"))\n",
       "[24] ((dim=2|id=647|\"S=1/2,Site,n=24\")', (dim=2|id=647|\"S=1/2,Site,n=24\"), (dim=1|id=731|\"Link,l=24\"), (dim=1|id=891|\"Link,l=23\"))\n",
       "[25] ((dim=2|id=585|\"S=1/2,Site,n=25\")', (dim=2|id=585|\"S=1/2,Site,n=25\"), (dim=1|id=248|\"Link,l=25\"), (dim=1|id=731|\"Link,l=24\"))\n",
       "[26] ((dim=2|id=982|\"S=1/2,Site,n=26\")', (dim=2|id=982|\"S=1/2,Site,n=26\"), (dim=1|id=245|\"Link,l=26\"), (dim=1|id=248|\"Link,l=25\"))\n",
       "[27] ((dim=2|id=249|\"S=1/2,Site,n=27\")', (dim=2|id=249|\"S=1/2,Site,n=27\"), (dim=1|id=117|\"Link,l=27\"), (dim=1|id=245|\"Link,l=26\"))\n",
       "[28] ((dim=2|id=109|\"S=1/2,Site,n=28\")', (dim=2|id=109|\"S=1/2,Site,n=28\"), (dim=1|id=315|\"Link,l=28\"), (dim=1|id=117|\"Link,l=27\"))\n",
       "[29] ((dim=2|id=373|\"S=1/2,Site,n=29\")', (dim=2|id=373|\"S=1/2,Site,n=29\"), (dim=1|id=77|\"Link,l=29\"), (dim=1|id=315|\"Link,l=28\"))\n",
       "[30] ((dim=2|id=390|\"S=1/2,Site,n=30\")', (dim=2|id=390|\"S=1/2,Site,n=30\"), (dim=1|id=356|\"Link,l=30\"), (dim=1|id=77|\"Link,l=29\"))\n",
       "[31] ((dim=2|id=504|\"S=1/2,Site,n=31\")', (dim=2|id=504|\"S=1/2,Site,n=31\"), (dim=1|id=886|\"Link,l=31\"), (dim=1|id=356|\"Link,l=30\"))\n",
       "[32] ((dim=2|id=42|\"S=1/2,Site,n=32\")', (dim=2|id=42|\"S=1/2,Site,n=32\"), (dim=1|id=542|\"Link,l=32\"), (dim=1|id=886|\"Link,l=31\"))\n",
       "[33] ((dim=2|id=872|\"S=1/2,Site,n=33\")', (dim=2|id=872|\"S=1/2,Site,n=33\"), (dim=1|id=889|\"Link,l=33\"), (dim=1|id=542|\"Link,l=32\"))\n",
       "[34] ((dim=2|id=4|\"S=1/2,Site,n=34\")', (dim=2|id=4|\"S=1/2,Site,n=34\"), (dim=1|id=576|\"Link,l=34\"), (dim=1|id=889|\"Link,l=33\"))\n",
       "[35] ((dim=2|id=274|\"S=1/2,Site,n=35\")', (dim=2|id=274|\"S=1/2,Site,n=35\"), (dim=1|id=226|\"Link,l=35\"), (dim=1|id=576|\"Link,l=34\"))\n",
       "[36] ((dim=2|id=741|\"S=1/2,Site,n=36\")', (dim=2|id=741|\"S=1/2,Site,n=36\"), (dim=1|id=708|\"Link,l=36\"), (dim=1|id=226|\"Link,l=35\"))\n",
       "[37] ((dim=2|id=53|\"S=1/2,Site,n=37\")', (dim=2|id=53|\"S=1/2,Site,n=37\"), (dim=1|id=35|\"Link,l=37\"), (dim=1|id=708|\"Link,l=36\"))\n",
       "[38] ((dim=2|id=806|\"S=1/2,Site,n=38\")', (dim=2|id=806|\"S=1/2,Site,n=38\"), (dim=1|id=479|\"Link,l=38\"), (dim=1|id=35|\"Link,l=37\"))\n",
       "[39] ((dim=2|id=573|\"S=1/2,Site,n=39\")', (dim=2|id=573|\"S=1/2,Site,n=39\"), (dim=1|id=123|\"Link,l=39\"), (dim=1|id=479|\"Link,l=38\"))\n",
       "[40] ((dim=2|id=42|\"S=1/2,Site,n=40\")', (dim=2|id=42|\"S=1/2,Site,n=40\"), (dim=1|id=691|\"Link,l=40\"), (dim=1|id=123|\"Link,l=39\"))\n",
       "[41] ((dim=2|id=129|\"S=1/2,Site,n=41\")', (dim=2|id=129|\"S=1/2,Site,n=41\"), (dim=1|id=340|\"Link,l=41\"), (dim=1|id=691|\"Link,l=40\"))\n",
       "[42] ((dim=2|id=931|\"S=1/2,Site,n=42\")', (dim=2|id=931|\"S=1/2,Site,n=42\"), (dim=1|id=674|\"Link,l=42\"), (dim=1|id=340|\"Link,l=41\"))\n",
       "[43] ((dim=2|id=551|\"S=1/2,Site,n=43\")', (dim=2|id=551|\"S=1/2,Site,n=43\"), (dim=1|id=43|\"Link,l=43\"), (dim=1|id=674|\"Link,l=42\"))\n",
       "[44] ((dim=2|id=722|\"S=1/2,Site,n=44\")', (dim=2|id=722|\"S=1/2,Site,n=44\"), (dim=1|id=782|\"Link,l=44\"), (dim=1|id=43|\"Link,l=43\"))\n",
       "[45] ((dim=2|id=378|\"S=1/2,Site,n=45\")', (dim=2|id=378|\"S=1/2,Site,n=45\"), (dim=1|id=984|\"Link,l=45\"), (dim=1|id=782|\"Link,l=44\"))\n",
       "[46] ((dim=2|id=887|\"S=1/2,Site,n=46\")', (dim=2|id=887|\"S=1/2,Site,n=46\"), (dim=1|id=301|\"Link,l=46\"), (dim=1|id=984|\"Link,l=45\"))\n",
       "[47] ((dim=2|id=428|\"S=1/2,Site,n=47\")', (dim=2|id=428|\"S=1/2,Site,n=47\"), (dim=1|id=660|\"Link,l=47\"), (dim=1|id=301|\"Link,l=46\"))\n",
       "[48] ((dim=2|id=925|\"S=1/2,Site,n=48\")', (dim=2|id=925|\"S=1/2,Site,n=48\"), (dim=1|id=947|\"Link,l=48\"), (dim=1|id=660|\"Link,l=47\"))\n",
       "[49] ((dim=2|id=80|\"S=1/2,Site,n=49\")', (dim=2|id=80|\"S=1/2,Site,n=49\"), (dim=1|id=110|\"Link,l=49\"), (dim=1|id=947|\"Link,l=48\"))\n",
       "[50] ((dim=2|id=565|\"S=1/2,Site,n=50\")', (dim=2|id=565|\"S=1/2,Site,n=50\"), (dim=1|id=110|\"Link,l=49\"))\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ρ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Garbage Collection** (references: https://cuda.juliagpu.org/stable/usage/memory/ and https://discourse.julialang.org/t/any-way-to-delete-an-object-and-free-memory/53600)\n",
    "\n",
    "This can be monitored using the Task Manager of Windows or using CUDA.memory_status():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 51.74% (16.422 GiB/31.739 GiB)\n",
      "Memory pool usage: 12.267 GiB (15.969 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.871440 seconds (66.52 k allocations: 5.257 GiB, 0.74% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.41397413650058e-16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#woGPU\n",
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 500 #The difference between times increases with this value.\n",
    "\n",
    "A = randomMPS(sites, bond_dimension)\n",
    "O = randomMPO(sites)\n",
    "\n",
    "@time begin \n",
    "    inner(A, apply(O, A))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.919983 seconds (242.50 k allocations: 21.390 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.413974138873696e-16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "A = NDTensors.cu(A)\n",
    "O = NDTensors.cu(O)\n",
    "\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As A has a bond_dimension of 600, the GPU used a lot of memory to perform the last operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 17.12% (5.433 GiB/31.739 GiB)\n",
      "Memory pool usage: 991.897 KiB (32.000 MiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Task Manager](CUDA_1.png)  -->\n",
    "\n",
    "<!-- <img src=\"CUDA_1.png\" alt=\"alt text\" width=\"400\" height=\"400\"/> -->\n",
    "\n",
    "If we try to run the code again, we must be careful because it could be slow because we do not have more GPU memory and ITensors has not clean all the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 31.71% (10.064 GiB/31.739 GiB)\n",
      "Memory pool usage: 1.937 MiB (32.000 MiB reserved)\n",
      "  0.877140 seconds (242.56 k allocations: 21.394 MiB)\n",
      "Effective GPU memory usage: 46.29% (14.693 GiB/31.739 GiB)\n",
      "Memory pool usage: 2.906 MiB (32.000 MiB reserved)\n",
      "  0.889068 seconds (242.69 k allocations: 21.406 MiB)\n",
      "Effective GPU memory usage: 60.88% (19.322 GiB/31.739 GiB)\n",
      "Memory pool usage: 3.875 MiB (32.000 MiB reserved)\n",
      "  0.893649 seconds (242.69 k allocations: 21.406 MiB)\n",
      "Effective GPU memory usage: 75.46% (23.951 GiB/31.739 GiB)\n",
      "Memory pool usage: 4.843 MiB (32.000 MiB reserved)\n",
      "  0.895097 seconds (242.68 k allocations: 21.405 MiB)\n",
      "Effective GPU memory usage: 90.05% (28.580 GiB/31.739 GiB)\n",
      "Memory pool usage: 5.812 MiB (32.000 MiB reserved)\n",
      "  0.898199 seconds (242.69 k allocations: 21.406 MiB)\n",
      "Effective GPU memory usage: 100.00% (31.738 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.781 MiB (32.000 MiB reserved)\n",
      "  1.092846 seconds (242.70 k allocations: 21.406 MiB)\n",
      "Effective GPU memory usage: 100.00% (31.738 GiB/31.739 GiB)\n",
      "Memory pool usage: 7.749 MiB (64.000 MiB reserved)\n",
      "  1.404927 seconds (242.70 k allocations: 21.406 MiB)\n",
      "Effective GPU memory usage: 100.00% (31.738 GiB/31.739 GiB)\n",
      "Memory pool usage: 8.718 MiB (64.000 MiB reserved)\n",
      "  1.392584 seconds (242.71 k allocations: 21.406 MiB)\n",
      "Effective GPU memory usage: 100.00% (31.738 GiB/31.739 GiB)\n",
      "Memory pool usage: 9.686 MiB (64.000 MiB reserved)\n",
      "  1.392901 seconds (242.70 k allocations: 21.406 MiB)\n",
      "Effective GPU memory usage: 100.00% (31.738 GiB/31.739 GiB)\n",
      "Memory pool usage: 10.655 MiB (64.000 MiB reserved)\n",
      "  1.396162 seconds (242.70 k allocations: 21.406 MiB)\n"
     ]
    }
   ],
   "source": [
    "for i = 1:10\n",
    "    @time begin \n",
    "        inner(A, apply(O, A))\n",
    "        CUDA.memory_status()    \n",
    "        # CUDA.reclaim()\n",
    "        # CUDA.memory_status()    \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we do not have more GPU the computer starts using the shared GPU memory (i.e. RAM), this generates a bottle neck and it could be even slower than just using CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 54.11% (17.174 GiB/31.739 GiB)\n",
      "Memory pool usage: 5.751 GiB (16.719 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to recover all the memory used to save the chache of the calculation we need to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.452791 seconds (98.26% gc time)\n",
      "  0.044091 seconds (10 allocations: 608 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time GC.gc(true)\n",
    "@time CUDA.reclaim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 19.84% (6.299 GiB/31.739 GiB)\n",
      "Memory pool usage: 5.751 GiB (5.844 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we clean in each step of the for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.796158 seconds (178.78 k allocations: 20.643 MiB)\n",
      "  0.466342 seconds (10 allocations: 608 bytes, 93.54% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.801689 seconds (178.77 k allocations: 20.643 MiB)\n",
      "  0.492212 seconds (10 allocations: 608 bytes, 94.12% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.814620 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.518652 seconds (10 allocations: 608 bytes, 93.98% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.804223 seconds (178.77 k allocations: 20.643 MiB)\n",
      "  0.480974 seconds (10 allocations: 608 bytes, 93.75% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.808694 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.453822 seconds (10 allocations: 608 bytes, 92.94% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.828224 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.437730 seconds (10 allocations: 608 bytes, 92.39% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.809149 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.445783 seconds (10 allocations: 608 bytes, 93.32% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.811245 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.491196 seconds (10 allocations: 608 bytes, 93.97% gc time)\n"
     ]
    }
   ],
   "source": [
    "for i = 1:8\n",
    "    @time begin \n",
    "        inner(A, apply(O, A))\n",
    "        CUDA.memory_status()    \n",
    "    end\n",
    "    @time begin\n",
    "        GC.gc(true)\n",
    "        CUDA.reclaim()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 20.81% (1.664 GiB/7.996 GiB)\n",
      "Memory pool usage: 481.346 MiB (512.000 MiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works, is better for the memory also takes some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple GPUs** https://cuda.juliagpu.org/stable/usage/multigpu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_all_gpus (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#monitoring multiples gpu functions:\n",
    "\n",
    "function memory_info_all_gpus(print_info = true)\n",
    "    \n",
    "    percentages = []\n",
    "\n",
    "    scale = 1/(1024^3) #converty bytes to GB\n",
    "    for (i, dev) in enumerate(CUDA.NVML.devices())\n",
    "\n",
    "        name = CUDA.NVML.name(dev) \n",
    "        mem_info = CUDA.NVML.memory_info(dev)\n",
    "        total = round(mem_info.total*scale, sigdigits=4)\n",
    "        used = round(mem_info.used*scale, sigdigits=4)\n",
    "        free = round(mem_info.free*scale, sigdigits=4)\n",
    "        percentage= round(used*100/total, sigdigits=4)\n",
    "        \n",
    "        print_info ? println(\"$name #$i memory usage: $percentage % ($used GB/ $total GB)\" ) : nothing\n",
    "        \n",
    "        append!(percentages, percentage)\n",
    "    end\n",
    "    \n",
    "    return percentages\n",
    "end\n",
    "\n",
    "function clean_all_gpus()\n",
    "    for i=reverse(0:length(CUDA.devices()) - 1)\n",
    "        global current_gpu = i\n",
    "        CUDA.device!(current_gpu)\n",
    "        GC.gc(true) \n",
    "        CUDA.reclaim()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 9.566 % (3.061 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 9.566\n",
       " 1.76"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all_gpus()\n",
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 3000 #The difference between times increases with this value.\n",
    "\n",
    "#wGPU\n",
    "A = NDTensors.cu(randomMPS(sites, bond_dimension); storagemode=CUDA.UnifiedMemory)\n",
    "O = NDTensors.cu(randomMPO(sites); storagemode=CUDA.UnifiedMemory);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50.590041 seconds (246.03 k allocations: 25.780 MiB, 0.01% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1878975780263433e-16"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 62.22 % (19.91 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 62.22\n",
       "  1.76"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time begin\n",
    "    for i=1:5\n",
    "        @time inner(A, apply(O, A))\n",
    "        memory_info_all_gpus()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 6.453 % (2.065 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 6.453\n",
       " 1.76"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all_gpus()\n",
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.884805 seconds (245.83 k allocations: 23.247 MiB)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 99.41 % (31.81 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 10.885261 seconds (245.98 k allocations: 23.259 MiB)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 99.41 % (31.81 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      "  9.227167 seconds (245.93 k allocations: 23.258 MiB, 0.24% gc time)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 99.41 % (31.81 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 11.051499 seconds (246.03 k allocations: 23.260 MiB)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 99.41 % (31.81 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 10.496104 seconds (245.96 k allocations: 23.258 MiB, 0.17% gc time)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 60.09 % (19.23 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 49.549965 seconds (1.23 M allocations: 116.322 MiB, 0.08% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "    for i=1:5\n",
    "        @time inner(A, apply(O, A))\n",
    "        CUDA.reclaim()\n",
    "        memory_info_all_gpus()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
