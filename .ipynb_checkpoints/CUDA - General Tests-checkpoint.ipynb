{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <center> Joaquin Peñuela-Parra </center>\n",
    "<center> Department of Mechanical Engineering and Materials Science </center>\n",
    "<center> University of Pittsburgh, Pittsburgh, Pennsylvania 15261, USA </center>  -->\n",
    "\n",
    "$$ \\textrm{Joaquin Penuela-Parra} $$\n",
    "$$ \\textrm{Department of Mechanical Engineering and Materials Science} $$\n",
    "$$ \\textrm{University of Pittsburgh, Pittsburgh, Pennsylvania 15261, USA} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using ITensors\n",
    "using CUDA #Nvidia GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.DeviceIterator() for 1 devices:\n",
       "0. NVIDIA GeForce RTX 4070 Laptop GPU"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 56.37% (4.507 GiB/7.996 GiB)\n",
      "Memory pool usage: 281.496 MiB (3.344 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general to use ITensor with GPU, we just need to use the function cu() or NDTensors.cu() to define the same ITensor Object inside the GPU Memory as a CUArray. The only difference between the two functions is that NDTensors.cu() preserves the element type of the tensors, while cu() converts to single precision. However, **single precision can generate problems in DMRG or TEBD** algorithms: https://itensor.discourse.group/t/tebd-with-gpu-error-with-eigen/1266/5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Block Sparse contraction**\n",
    "\n",
    "Despite this type of contractions are still in development (https://itensor.discourse.group/t/ann-initial-release-of-new-itensor-gpu-backends/1227/3), we already can see some advantage of the use of GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.026541 seconds (64 allocations: 30.526 MiB)\n"
     ]
    }
   ],
   "source": [
    "#woGPU\n",
    "i = Index([QN(0) => 1000, QN(1) => 1000]);\n",
    "A = randomITensor(i', dag(i));\n",
    "\n",
    "@time (A)'*(A);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ITensor"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000313 seconds (196 allocations: 11.594 KiB)\n",
      "  0.015404 seconds (64 allocations: 15.267 MiB)\n"
     ]
    }
   ],
   "source": [
    "#wGPU\n",
    "A = cu(A)\n",
    "\n",
    "@time (A)'*(A)\n",
    "\n",
    "A_cpu = NDTensors.cpu(A) #This is how you can go back to the cpu.\n",
    "@time (A_cpu)'*(A_cpu);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Excessive output truncated after 10485760 bytes."
     ]
    },
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=848)' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=848) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float32, CuArray{Float32, 1, CUDA.DeviceMemory}, 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show A #We can see that it is in the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If A is a CuArray and we define another variable in terms of A, that variable will be also a CuArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=848)' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=848) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float32, CuArray{Float32, 1, CUDA.DeviceMemory}, 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = 2*A - 3*A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ITensor ord=2\n",
       "(dim=2000|id=848)'' <Out>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "(dim=2000|id=848) <In>\n",
       " 1: QN(0) => 1000\n",
       " 2: QN(1) => 1000\n",
       "NDTensors.BlockSparse{Float32, CuArray{Float32, 1, CUDA.DeviceMemory}, 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000338 seconds (196 allocations: 11.594 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time (C)'*(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expectation values contractions (inner and apply functions)**\n",
    "\n",
    "Pure states: $\\langle A \\rangle = \\langle \\Psi | A | \\Psi \\rangle$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.453439719106022e-16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.899990 seconds (65.65 k allocations: 3.411 GiB, 4.11% gc time)\n"
     ]
    }
   ],
   "source": [
    "#woGPU\n",
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 400 #The difference between times increases with this value.\n",
    "\n",
    "A = randomMPS(sites, bond_dimension)\n",
    "O = randomMPO(sites)\n",
    "\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.481926 seconds (65.65 k allocations: 3.411 GiB, 2.39% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.453439719106022e-16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.775505 seconds (159.57 k allocations: 19.890 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.453439710454487e-16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "A = NDTensors.cu(A)\n",
    "O = NDTensors.cu(O)\n",
    "\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed States: $\\langle A \\rangle = \\textrm{Tr} (\\rho A)$. Take for example when $\\rho$ is an identity matrix, and A is a random operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.041562 seconds (113.03 k allocations: 30.104 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.677849879209959e-18"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#woGPU\n",
    "ρ = MPO(sites, \"Id\")\n",
    "O = randomMPO(sites)\n",
    "\n",
    "@time tr(apply(ρ, O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.226028 seconds (257.09 k allocations: 33.948 MiB)\n",
      "  0.230393 seconds (252.35 k allocations: 36.490 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.677849879209973e-18"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "ρ = NDTensors.cu(ρ)\n",
    "O = NDTensors.cu(O)\n",
    "\n",
    "@time tr(apply(ρ, O))\n",
    "\n",
    "#We also can perform the trace manually by contracting the bra and ket site indices of each site with delta tensors. This takes a similar time:\n",
    "I = MPO(sites, \"Id\") #Contains all the delta tensors.\n",
    "I = NDTensors.cu(I)\n",
    "\n",
    "@time inner(I, apply(ρ, O))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why it is not faster?**. I think that in this case we do not see advantage because the bond dimension of $ρ$ is 1. If we have an MPO with a bigger bond dimension, probably we will see the advantage as in the case of MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPO\n",
       "[1] ((dim=2|id=113|\"S=1/2,Site,n=1\")', (dim=2|id=113|\"S=1/2,Site,n=1\"), (dim=1|id=238|\"Link,l=1\"))\n",
       "[2] ((dim=2|id=398|\"S=1/2,Site,n=2\")', (dim=2|id=398|\"S=1/2,Site,n=2\"), (dim=1|id=441|\"Link,l=2\"), (dim=1|id=238|\"Link,l=1\"))\n",
       "[3] ((dim=2|id=242|\"S=1/2,Site,n=3\")', (dim=2|id=242|\"S=1/2,Site,n=3\"), (dim=1|id=11|\"Link,l=3\"), (dim=1|id=441|\"Link,l=2\"))\n",
       "[4] ((dim=2|id=217|\"S=1/2,Site,n=4\")', (dim=2|id=217|\"S=1/2,Site,n=4\"), (dim=1|id=298|\"Link,l=4\"), (dim=1|id=11|\"Link,l=3\"))\n",
       "[5] ((dim=2|id=697|\"S=1/2,Site,n=5\")', (dim=2|id=697|\"S=1/2,Site,n=5\"), (dim=1|id=248|\"Link,l=5\"), (dim=1|id=298|\"Link,l=4\"))\n",
       "[6] ((dim=2|id=839|\"S=1/2,Site,n=6\")', (dim=2|id=839|\"S=1/2,Site,n=6\"), (dim=1|id=39|\"Link,l=6\"), (dim=1|id=248|\"Link,l=5\"))\n",
       "[7] ((dim=2|id=267|\"S=1/2,Site,n=7\")', (dim=2|id=267|\"S=1/2,Site,n=7\"), (dim=1|id=365|\"Link,l=7\"), (dim=1|id=39|\"Link,l=6\"))\n",
       "[8] ((dim=2|id=562|\"S=1/2,Site,n=8\")', (dim=2|id=562|\"S=1/2,Site,n=8\"), (dim=1|id=247|\"Link,l=8\"), (dim=1|id=365|\"Link,l=7\"))\n",
       "[9] ((dim=2|id=519|\"S=1/2,Site,n=9\")', (dim=2|id=519|\"S=1/2,Site,n=9\"), (dim=1|id=382|\"Link,l=9\"), (dim=1|id=247|\"Link,l=8\"))\n",
       "[10] ((dim=2|id=848|\"S=1/2,Site,n=10\")', (dim=2|id=848|\"S=1/2,Site,n=10\"), (dim=1|id=222|\"Link,l=10\"), (dim=1|id=382|\"Link,l=9\"))\n",
       "[11] ((dim=2|id=556|\"S=1/2,Site,n=11\")', (dim=2|id=556|\"S=1/2,Site,n=11\"), (dim=1|id=128|\"Link,l=11\"), (dim=1|id=222|\"Link,l=10\"))\n",
       "[12] ((dim=2|id=432|\"S=1/2,Site,n=12\")', (dim=2|id=432|\"S=1/2,Site,n=12\"), (dim=1|id=688|\"Link,l=12\"), (dim=1|id=128|\"Link,l=11\"))\n",
       "[13] ((dim=2|id=813|\"S=1/2,Site,n=13\")', (dim=2|id=813|\"S=1/2,Site,n=13\"), (dim=1|id=436|\"Link,l=13\"), (dim=1|id=688|\"Link,l=12\"))\n",
       "[14] ((dim=2|id=989|\"S=1/2,Site,n=14\")', (dim=2|id=989|\"S=1/2,Site,n=14\"), (dim=1|id=762|\"Link,l=14\"), (dim=1|id=436|\"Link,l=13\"))\n",
       "[15] ((dim=2|id=805|\"S=1/2,Site,n=15\")', (dim=2|id=805|\"S=1/2,Site,n=15\"), (dim=1|id=94|\"Link,l=15\"), (dim=1|id=762|\"Link,l=14\"))\n",
       "[16] ((dim=2|id=568|\"S=1/2,Site,n=16\")', (dim=2|id=568|\"S=1/2,Site,n=16\"), (dim=1|id=329|\"Link,l=16\"), (dim=1|id=94|\"Link,l=15\"))\n",
       "[17] ((dim=2|id=414|\"S=1/2,Site,n=17\")', (dim=2|id=414|\"S=1/2,Site,n=17\"), (dim=1|id=465|\"Link,l=17\"), (dim=1|id=329|\"Link,l=16\"))\n",
       "[18] ((dim=2|id=948|\"S=1/2,Site,n=18\")', (dim=2|id=948|\"S=1/2,Site,n=18\"), (dim=1|id=181|\"Link,l=18\"), (dim=1|id=465|\"Link,l=17\"))\n",
       "[19] ((dim=2|id=917|\"S=1/2,Site,n=19\")', (dim=2|id=917|\"S=1/2,Site,n=19\"), (dim=1|id=179|\"Link,l=19\"), (dim=1|id=181|\"Link,l=18\"))\n",
       "[20] ((dim=2|id=938|\"S=1/2,Site,n=20\")', (dim=2|id=938|\"S=1/2,Site,n=20\"), (dim=1|id=393|\"Link,l=20\"), (dim=1|id=179|\"Link,l=19\"))\n",
       "[21] ((dim=2|id=84|\"S=1/2,Site,n=21\")', (dim=2|id=84|\"S=1/2,Site,n=21\"), (dim=1|id=540|\"Link,l=21\"), (dim=1|id=393|\"Link,l=20\"))\n",
       "[22] ((dim=2|id=423|\"S=1/2,Site,n=22\")', (dim=2|id=423|\"S=1/2,Site,n=22\"), (dim=1|id=510|\"Link,l=22\"), (dim=1|id=540|\"Link,l=21\"))\n",
       "[23] ((dim=2|id=466|\"S=1/2,Site,n=23\")', (dim=2|id=466|\"S=1/2,Site,n=23\"), (dim=1|id=345|\"Link,l=23\"), (dim=1|id=510|\"Link,l=22\"))\n",
       "[24] ((dim=2|id=123|\"S=1/2,Site,n=24\")', (dim=2|id=123|\"S=1/2,Site,n=24\"), (dim=1|id=5|\"Link,l=24\"), (dim=1|id=345|\"Link,l=23\"))\n",
       "[25] ((dim=2|id=773|\"S=1/2,Site,n=25\")', (dim=2|id=773|\"S=1/2,Site,n=25\"), (dim=1|id=565|\"Link,l=25\"), (dim=1|id=5|\"Link,l=24\"))\n",
       "[26] ((dim=2|id=752|\"S=1/2,Site,n=26\")', (dim=2|id=752|\"S=1/2,Site,n=26\"), (dim=1|id=258|\"Link,l=26\"), (dim=1|id=565|\"Link,l=25\"))\n",
       "[27] ((dim=2|id=649|\"S=1/2,Site,n=27\")', (dim=2|id=649|\"S=1/2,Site,n=27\"), (dim=1|id=900|\"Link,l=27\"), (dim=1|id=258|\"Link,l=26\"))\n",
       "[28] ((dim=2|id=928|\"S=1/2,Site,n=28\")', (dim=2|id=928|\"S=1/2,Site,n=28\"), (dim=1|id=556|\"Link,l=28\"), (dim=1|id=900|\"Link,l=27\"))\n",
       "[29] ((dim=2|id=208|\"S=1/2,Site,n=29\")', (dim=2|id=208|\"S=1/2,Site,n=29\"), (dim=1|id=805|\"Link,l=29\"), (dim=1|id=556|\"Link,l=28\"))\n",
       "[30] ((dim=2|id=835|\"S=1/2,Site,n=30\")', (dim=2|id=835|\"S=1/2,Site,n=30\"), (dim=1|id=659|\"Link,l=30\"), (dim=1|id=805|\"Link,l=29\"))\n",
       "[31] ((dim=2|id=436|\"S=1/2,Site,n=31\")', (dim=2|id=436|\"S=1/2,Site,n=31\"), (dim=1|id=131|\"Link,l=31\"), (dim=1|id=659|\"Link,l=30\"))\n",
       "[32] ((dim=2|id=739|\"S=1/2,Site,n=32\")', (dim=2|id=739|\"S=1/2,Site,n=32\"), (dim=1|id=114|\"Link,l=32\"), (dim=1|id=131|\"Link,l=31\"))\n",
       "[33] ((dim=2|id=763|\"S=1/2,Site,n=33\")', (dim=2|id=763|\"S=1/2,Site,n=33\"), (dim=1|id=933|\"Link,l=33\"), (dim=1|id=114|\"Link,l=32\"))\n",
       "[34] ((dim=2|id=875|\"S=1/2,Site,n=34\")', (dim=2|id=875|\"S=1/2,Site,n=34\"), (dim=1|id=248|\"Link,l=34\"), (dim=1|id=933|\"Link,l=33\"))\n",
       "[35] ((dim=2|id=508|\"S=1/2,Site,n=35\")', (dim=2|id=508|\"S=1/2,Site,n=35\"), (dim=1|id=652|\"Link,l=35\"), (dim=1|id=248|\"Link,l=34\"))\n",
       "[36] ((dim=2|id=548|\"S=1/2,Site,n=36\")', (dim=2|id=548|\"S=1/2,Site,n=36\"), (dim=1|id=619|\"Link,l=36\"), (dim=1|id=652|\"Link,l=35\"))\n",
       "[37] ((dim=2|id=388|\"S=1/2,Site,n=37\")', (dim=2|id=388|\"S=1/2,Site,n=37\"), (dim=1|id=28|\"Link,l=37\"), (dim=1|id=619|\"Link,l=36\"))\n",
       "[38] ((dim=2|id=175|\"S=1/2,Site,n=38\")', (dim=2|id=175|\"S=1/2,Site,n=38\"), (dim=1|id=394|\"Link,l=38\"), (dim=1|id=28|\"Link,l=37\"))\n",
       "[39] ((dim=2|id=53|\"S=1/2,Site,n=39\")', (dim=2|id=53|\"S=1/2,Site,n=39\"), (dim=1|id=16|\"Link,l=39\"), (dim=1|id=394|\"Link,l=38\"))\n",
       "[40] ((dim=2|id=236|\"S=1/2,Site,n=40\")', (dim=2|id=236|\"S=1/2,Site,n=40\"), (dim=1|id=830|\"Link,l=40\"), (dim=1|id=16|\"Link,l=39\"))\n",
       "[41] ((dim=2|id=669|\"S=1/2,Site,n=41\")', (dim=2|id=669|\"S=1/2,Site,n=41\"), (dim=1|id=837|\"Link,l=41\"), (dim=1|id=830|\"Link,l=40\"))\n",
       "[42] ((dim=2|id=434|\"S=1/2,Site,n=42\")', (dim=2|id=434|\"S=1/2,Site,n=42\"), (dim=1|id=164|\"Link,l=42\"), (dim=1|id=837|\"Link,l=41\"))\n",
       "[43] ((dim=2|id=693|\"S=1/2,Site,n=43\")', (dim=2|id=693|\"S=1/2,Site,n=43\"), (dim=1|id=243|\"Link,l=43\"), (dim=1|id=164|\"Link,l=42\"))\n",
       "[44] ((dim=2|id=202|\"S=1/2,Site,n=44\")', (dim=2|id=202|\"S=1/2,Site,n=44\"), (dim=1|id=889|\"Link,l=44\"), (dim=1|id=243|\"Link,l=43\"))\n",
       "[45] ((dim=2|id=885|\"S=1/2,Site,n=45\")', (dim=2|id=885|\"S=1/2,Site,n=45\"), (dim=1|id=13|\"Link,l=45\"), (dim=1|id=889|\"Link,l=44\"))\n",
       "[46] ((dim=2|id=817|\"S=1/2,Site,n=46\")', (dim=2|id=817|\"S=1/2,Site,n=46\"), (dim=1|id=288|\"Link,l=46\"), (dim=1|id=13|\"Link,l=45\"))\n",
       "[47] ((dim=2|id=50|\"S=1/2,Site,n=47\")', (dim=2|id=50|\"S=1/2,Site,n=47\"), (dim=1|id=845|\"Link,l=47\"), (dim=1|id=288|\"Link,l=46\"))\n",
       "[48] ((dim=2|id=550|\"S=1/2,Site,n=48\")', (dim=2|id=550|\"S=1/2,Site,n=48\"), (dim=1|id=69|\"Link,l=48\"), (dim=1|id=845|\"Link,l=47\"))\n",
       "[49] ((dim=2|id=574|\"S=1/2,Site,n=49\")', (dim=2|id=574|\"S=1/2,Site,n=49\"), (dim=1|id=910|\"Link,l=49\"), (dim=1|id=69|\"Link,l=48\"))\n",
       "[50] ((dim=2|id=518|\"S=1/2,Site,n=50\")', (dim=2|id=518|\"S=1/2,Site,n=50\"), (dim=1|id=910|\"Link,l=49\"))\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ρ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Garbage Collection** (references: https://cuda.juliagpu.org/stable/usage/memory/ and https://discourse.julialang.org/t/any-way-to-delete-an-object-and-free-memory/53600)\n",
    "\n",
    "This can be monitored using the Task Manager of Windows or using CUDA.memory_status():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 56.37% (4.507 GiB/7.996 GiB)\n",
      "Memory pool usage: 3.223 GiB (3.344 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#woGPU\n",
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 500 #The difference between times increases with this value.\n",
    "\n",
    "A = randomMPS(sites, bond_dimension)\n",
    "O = randomMPO(sites)\n",
    "\n",
    "@time begin \n",
    "    inner(A, apply(O, A))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.531794 seconds (159.59 k allocations: 19.890 MiB, 2.34% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.5617907963743223e-16"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wGPU\n",
    "A = NDTensors.cu(A)\n",
    "O = NDTensors.cu(O)\n",
    "\n",
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As A has a bond_dimension of 600, the GPU used a lot of memory to perform the last operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 2.639 GiB (3.875 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Task Manager](CUDA_1.png)  -->\n",
    "\n",
    "<!-- <img src=\"CUDA_1.png\" alt=\"alt text\" width=\"400\" height=\"400\"/> -->\n",
    "\n",
    "If we try to run the code again, we must be careful because it could be slow because we do not have more GPU memory and ITensors has not clean all the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 2.446 GiB (3.875 GiB reserved)\n",
      "  1.546038 seconds (159.65 k allocations: 19.895 MiB, 0.79% gc time)\n",
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 2.322 GiB (3.875 GiB reserved)\n",
      "  1.526758 seconds (159.79 k allocations: 19.906 MiB, 0.33% gc time)\n",
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 2.198 GiB (3.875 GiB reserved)\n",
      "  1.508424 seconds (159.78 k allocations: 19.906 MiB, 0.18% gc time)\n",
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 2.074 GiB (3.875 GiB reserved)\n",
      "  1.502198 seconds (159.78 k allocations: 19.906 MiB, 0.19% gc time)\n",
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 1.950 GiB (3.875 GiB reserved)\n",
      "  1.494142 seconds (159.91 k allocations: 19.915 MiB, 0.19% gc time)\n",
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 1.826 GiB (3.875 GiB reserved)\n",
      "  1.502902 seconds (159.78 k allocations: 19.906 MiB, 0.19% gc time)\n",
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 1.702 GiB (3.875 GiB reserved)\n",
      "  1.501920 seconds (159.78 k allocations: 19.905 MiB, 0.20% gc time)\n",
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 1.578 GiB (3.875 GiB reserved)\n",
      "  1.501291 seconds (159.78 k allocations: 19.905 MiB, 0.20% gc time)\n",
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 1.454 GiB (3.875 GiB reserved)\n",
      "  1.500471 seconds (159.78 k allocations: 19.906 MiB, 0.22% gc time)\n",
      "Effective GPU memory usage: 63.02% (5.039 GiB/7.996 GiB)\n",
      "Memory pool usage: 1.330 GiB (3.875 GiB reserved)\n",
      "  1.499908 seconds (159.78 k allocations: 19.906 MiB, 0.19% gc time)\n"
     ]
    }
   ],
   "source": [
    "for i = 1:10\n",
    "    @time begin \n",
    "        inner(A, apply(O, A))\n",
    "        CUDA.memory_status()    \n",
    "        # CUDA.reclaim()\n",
    "        # CUDA.memory_status()    \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we do not have more GPU the computer starts using the shared GPU memory (i.e. RAM), this generates a bottle neck and it could be even slower than just using CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 54.11% (17.174 GiB/31.739 GiB)\n",
      "Memory pool usage: 5.751 GiB (16.719 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to recover all the memory used to save the chache of the calculation we need to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.232856 seconds (99.16% gc time)\n",
      "  0.045881 seconds (10 allocations: 608 bytes)\n"
     ]
    }
   ],
   "source": [
    "@time GC.gc(true)\n",
    "@time CUDA.reclaim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 19.84% (6.299 GiB/31.739 GiB)\n",
      "Memory pool usage: 5.751 GiB (5.844 GiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we clean in each step of the for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.796158 seconds (178.78 k allocations: 20.643 MiB)\n",
      "  0.466342 seconds (10 allocations: 608 bytes, 93.54% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.801689 seconds (178.77 k allocations: 20.643 MiB)\n",
      "  0.492212 seconds (10 allocations: 608 bytes, 94.12% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.814620 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.518652 seconds (10 allocations: 608 bytes, 93.98% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.804223 seconds (178.77 k allocations: 20.643 MiB)\n",
      "  0.480974 seconds (10 allocations: 608 bytes, 93.75% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.808694 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.453822 seconds (10 allocations: 608 bytes, 92.94% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.828224 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.437730 seconds (10 allocations: 608 bytes, 92.39% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.809149 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.445783 seconds (10 allocations: 608 bytes, 93.32% gc time)\n",
      "Effective GPU memory usage: 22.98% (7.293 GiB/31.739 GiB)\n",
      "Memory pool usage: 6.901 GiB (6.906 GiB reserved)\n",
      "  0.811245 seconds (178.77 k allocations: 20.644 MiB)\n",
      "  0.491196 seconds (10 allocations: 608 bytes, 93.97% gc time)\n"
     ]
    }
   ],
   "source": [
    "for i = 1:8\n",
    "    @time begin \n",
    "        inner(A, apply(O, A))\n",
    "        CUDA.memory_status()    \n",
    "    end\n",
    "    @time begin\n",
    "        GC.gc(true)\n",
    "        CUDA.reclaim()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective GPU memory usage: 20.81% (1.664 GiB/7.996 GiB)\n",
      "Memory pool usage: 481.346 MiB (512.000 MiB reserved)\n"
     ]
    }
   ],
   "source": [
    "CUDA.memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works, is better for the memory also takes some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple GPUs** https://cuda.juliagpu.org/stable/usage/multigpu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_all_gpus (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#monitoring multiples gpu functions:\n",
    "\n",
    "function memory_info_all_gpus(print_info = true)\n",
    "    \n",
    "    percentages = []\n",
    "\n",
    "    scale = 1/(1024^3) #converty bytes to GB\n",
    "    for (i, dev) in enumerate(CUDA.NVML.devices())\n",
    "\n",
    "        name = CUDA.NVML.name(dev) \n",
    "        mem_info = CUDA.NVML.memory_info(dev)\n",
    "        total = round(mem_info.total*scale, sigdigits=4)\n",
    "        used = round(mem_info.used*scale, sigdigits=4)\n",
    "        free = round(mem_info.free*scale, sigdigits=4)\n",
    "        percentage= round(used*100/total, sigdigits=4)\n",
    "        \n",
    "        print_info ? println(\"$name #$i memory usage: $percentage % ($used GB/ $total GB)\" ) : nothing\n",
    "        \n",
    "        append!(percentages, percentage)\n",
    "    end\n",
    "    \n",
    "    return percentages\n",
    "end\n",
    "\n",
    "function clean_all_gpus()\n",
    "    for i=reverse(0:length(CUDA.devices()) - 1)\n",
    "        global current_gpu = i\n",
    "        CUDA.device!(current_gpu)\n",
    "        GC.gc(true) \n",
    "        CUDA.reclaim()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 9.566 % (3.061 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 9.566\n",
       " 1.76"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all_gpus()\n",
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sites = siteinds(\"S=1/2\",50)\n",
    "bond_dimension = 3000 #The difference between times increases with this value.\n",
    "\n",
    "#wGPU\n",
    "A = NDTensors.cu(randomMPS(sites, bond_dimension); storagemode=CUDA.UnifiedMemory)\n",
    "O = NDTensors.cu(randomMPO(sites); storagemode=CUDA.UnifiedMemory);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50.590041 seconds (246.03 k allocations: 25.780 MiB, 0.01% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1878975780263433e-16"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time inner(A, apply(O, A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 62.22 % (19.91 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 62.22\n",
       "  1.76"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50.511294 seconds (246.04 k allocations: 25.781 MiB)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 100.0 % (32.0 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 53.646136 seconds (246.12 k allocations: 25.790 MiB, 0.24% gc time)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 100.0 % (32.0 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 51.979540 seconds (246.16 k allocations: 25.792 MiB)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 100.0 % (32.0 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ ~/.julia/packages/CUDA/75aiI/lib/utils/call.jl:220 [inlined]",
      "  [2] macro expansion",
      "    @ ~/.julia/packages/CUDA/75aiI/lib/cusolver/libcusolver.jl:3054 [inlined]",
      "  [3] #508",
      "    @ ~/.julia/packages/CUDA/75aiI/lib/utils/call.jl:35 [inlined]",
      "  [4] retry_reclaim",
      "    @ ~/.julia/packages/CUDA/75aiI/src/memory.jl:434 [inlined]",
      "  [5] check",
      "    @ ~/.julia/packages/CUDA/75aiI/lib/cusolver/libcusolver.jl:24 [inlined]",
      "  [6] cusolverDnDsyevd",
      "    @ ~/.julia/packages/CUDA/75aiI/lib/utils/call.jl:34 [inlined]",
      "  [7] (::CUDA.CUSOLVER.var\"#1365#1367\"{Char, Char, CuArray{Float64, 2, CUDA.UnifiedMemory}, CuArray{Int32, 1, CUDA.DeviceMemory}, CuArray{Float64, 1, CUDA.DeviceMemory}, Int64, Int64})(buffer::CuArray{UInt8, 1, CUDA.DeviceMemory})",
      "    @ CUDA.CUSOLVER ~/.julia/packages/CUDA/75aiI/lib/cusolver/dense.jl:640",
      "  [8] with_workspaces(f::CUDA.CUSOLVER.var\"#1365#1367\"{Char, Char, CuArray{Float64, 2, CUDA.UnifiedMemory}, CuArray{Int32, 1, CUDA.DeviceMemory}, CuArray{Float64, 1, CUDA.DeviceMemory}, Int64, Int64}, cache_gpu::Nothing, cache_cpu::Nothing, size_gpu::CUDA.CUSOLVER.var\"#bufferSize#1366\"{Char, Char, CuArray{Float64, 2, CUDA.UnifiedMemory}, CuArray{Float64, 1, CUDA.DeviceMemory}, Int64, Int64}, size_cpu::Int64)",
      "    @ CUDA.APIUtils ~/.julia/packages/CUDA/75aiI/lib/utils/call.jl:131",
      "  [9] with_workspace",
      "    @ ~/.julia/packages/CUDA/75aiI/lib/utils/call.jl:67 [inlined]",
      " [10] syevd!(jobz::Char, uplo::Char, A::CuArray{Float64, 2, CUDA.UnifiedMemory})",
      "    @ CUDA.CUSOLVER ~/.julia/packages/CUDA/75aiI/lib/cusolver/dense.jl:639",
      " [11] eigen(A::LinearAlgebra.Symmetric{Float64, CuArray{Float64, 2, CUDA.UnifiedMemory}})",
      "    @ CUDA.CUSOLVER ~/.julia/packages/CUDA/75aiI/lib/cusolver/linalg.jl:117",
      " [12] eigen",
      "    @ ~/.julia/packages/CUDA/75aiI/lib/cusolver/linalg.jl:124 [inlined]",
      " [13] eigen",
      "    @ ~/.julia/packages/NDTensors/cB202/src/lib/Expose/src/functions/linearalgebra.jl:24 [inlined]",
      " [14] eigen(T::LinearAlgebra.Hermitian{Float64, NDTensors.DenseTensor{Float64, 2, Tuple{Index{Int64}, Index{Int64}}, NDTensors.Dense{Float64, CuArray{Float64, 1, CUDA.UnifiedMemory}}}}; mindim::Int64, maxdim::Int64, cutoff::Float64, use_absolute_cutoff::Nothing, use_relative_cutoff::Nothing)",
      "    @ NDTensors ~/.julia/packages/NDTensors/cB202/src/linearalgebra/linearalgebra.jl:178",
      " [15] eigen(A::ITensor, Linds::Vector{Index{Int64}}, Rinds::Vector{Index{Int64}}; mindim::Int64, maxdim::Int64, cutoff::Float64, use_absolute_cutoff::Nothing, use_relative_cutoff::Nothing, ishermitian::Bool, tags::ITensors.TagSets.GenericTagSet{BitIntegers.UInt256, 4}, lefttags::Nothing, righttags::Nothing, plev::Nothing, leftplev::Nothing, rightplev::Nothing)",
      "    @ ITensors ~/.julia/packages/ITensors/rH5UO/src/tensor_operations/matrix_decomposition.jl:378",
      " [16] contract(::NDTensors.BackendSelection.Algorithm{:densitymatrix, @NamedTuple{}}, A::MPO, ψ::MPS; cutoff::Float64, maxdim::Int64, mindim::Int64, normalize::Bool, kwargs::@Kwargs{})",
      "    @ ITensors.ITensorMPS ~/.julia/packages/ITensors/rH5UO/src/lib/ITensorMPS/src/mpo.jl:762",
      " [17] contract(::NDTensors.BackendSelection.Algorithm{:densitymatrix, @NamedTuple{}}, A::MPO, ψ::MPS)",
      "    @ ITensors.ITensorMPS ~/.julia/packages/ITensors/rH5UO/src/lib/ITensorMPS/src/mpo.jl:691",
      " [18] #apply#454",
      "    @ ~/.julia/packages/ITensors/rH5UO/src/lib/ITensorMPS/src/mpo.jl:604 [inlined]",
      " [19] product",
      "    @ ~/.julia/packages/ITensors/rH5UO/src/lib/ITensorMPS/src/mpo.jl:603 [inlined]",
      " [20] #apply#453",
      "    @ ~/.julia/packages/ITensors/rH5UO/src/lib/ITensorMPS/src/mpo.jl:600 [inlined]",
      " [21] product(A::MPO, ψ::MPS)",
      "    @ ITensors.ITensorMPS ~/.julia/packages/ITensors/rH5UO/src/lib/ITensorMPS/src/mpo.jl:599",
      " [22] macro expansion",
      "    @ ./timing.jl:279 [inlined]",
      " [23] macro expansion",
      "    @ ./In[79]:3 [inlined]",
      " [24] macro expansion",
      "    @ ./timing.jl:279 [inlined]",
      " [25] top-level scope",
      "    @ ./In[79]:1"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "    for i=1:5\n",
    "        @time inner(A, apply(O, A))\n",
    "        memory_info_all_gpus()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-SXM2-32GB #1 memory usage: 6.453 % (2.065 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Any}:\n",
       " 6.453\n",
       " 1.76"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all_gpus()\n",
    "memory_info_all_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.884805 seconds (245.83 k allocations: 23.247 MiB)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 99.41 % (31.81 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 10.885261 seconds (245.98 k allocations: 23.259 MiB)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 99.41 % (31.81 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      "  9.227167 seconds (245.93 k allocations: 23.258 MiB, 0.24% gc time)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 99.41 % (31.81 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 11.051499 seconds (246.03 k allocations: 23.260 MiB)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 99.41 % (31.81 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 10.496104 seconds (245.96 k allocations: 23.258 MiB, 0.17% gc time)\n",
      "Tesla V100-SXM2-32GB #1 memory usage: 60.09 % (19.23 GB/ 32.0 GB)\n",
      "Tesla V100-SXM2-32GB #2 memory usage: 1.76 % (0.5632 GB/ 32.0 GB)\n",
      " 49.549965 seconds (1.23 M allocations: 116.322 MiB, 0.08% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time begin\n",
    "    for i=1:5\n",
    "        @time inner(A, apply(O, A))\n",
    "        CUDA.reclaim()\n",
    "        memory_info_all_gpus()\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.3",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
